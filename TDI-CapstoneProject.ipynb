{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09886df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60db88",
   "metadata": {},
   "source": [
    "# SQLite and Data Preprocessing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb3389",
   "metadata": {},
   "source": [
    "### SQL to Dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sqlalchemy import inspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///microstructures.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e18fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MicrostrucureData = sqlalchemy.MetaData(bind = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### JOINS the micrograph table to the sample data table\n",
    "\n",
    "\n",
    "micrographs = \"\"\"\n",
    "\n",
    "SELECT *\n",
    "FROM micrograph JOIN sample ON sample_id = sample_key\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  This is the main dataframe\n",
    "micrographs_df = pd.read_sql_query(micrographs, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee4094",
   "metadata": {},
   "source": [
    "### Custom Transformers for Data Preprocessing\n",
    "\n",
    "The anneal time is in minutes and hours, and we will convert evething to minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToMinute(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, dataseries):\n",
    "        self.dataseries = dataseries\n",
    "        self.multi = self.dataseries.apply(self._M_to_K)\n",
    "        \n",
    "    def _M_to_K(self, char):\n",
    "        if char == 'H':\n",
    "            return 60\n",
    "        if char == 'M':\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        \n",
    "        return X*self.multi\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9d918",
   "metadata": {},
   "source": [
    "## This is our main preprocssing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6588c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  This is our main data frame before preprocessing\n",
    "\n",
    "preprocess_micrographs_df = micrographs_df[['path',\n",
    "                                 'sample_id',\n",
    "                                 'anneal_time',\n",
    "                                 'anneal_time_unit',\n",
    "                                 'anneal_temperature',\n",
    "                                 'cool_method'\n",
    "                                ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158be1d",
   "metadata": {},
   "source": [
    "# Transfer Learning:  InceptionV3 Regeression Model \n",
    "\n",
    "## Inverse Temperature and Log Time with stratified train-test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a04e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_minute = ToMinute(preprocess_micrographs_df['anneal_time_unit'])\n",
    "\n",
    "Kelvin_minute_micrograph = preprocess_micrographs_df.copy()\n",
    "Kelvin_minute_micrograph['anneal_temperature_Kelvin'] = Kelvin_minute_micrograph['anneal_temperature'] + 273.15\n",
    "Kelvin_minute_micrograph['anneal_time_minutes'] = to_minute.transform(preprocess_micrographs_df['anneal_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90871cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kelvin_minute_micrograph_dropna = Kelvin_minute_micrograph[['path',\n",
    "                                              'sample_id', \n",
    "                                              'anneal_temperature_Kelvin', \n",
    "                                              'anneal_time_minutes','cool_method']].dropna()\n",
    "\n",
    "Kelvin_minute_micrograph_dropna['log_time'] = Kelvin_minute_micrograph_dropna['anneal_time_minutes'].apply(lambda x : np.log(x))\n",
    "Kelvin_minute_micrograph_dropna['inverse_anneal_temperature_Kelvin'] = 1/Kelvin_minute_micrograph_dropna['anneal_temperature_Kelvin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColScaler = ColumnTransformer([('scaler',StandardScaler(),['inverse_anneal_temperature_Kelvin',\n",
    "                                                                   'log_time',\n",
    "                                                                  ])], \n",
    "                                                                  remainder = 'passthrough')\n",
    "\n",
    "ColScaler.set_output(transform ='pandas')\n",
    "\n",
    "scaled_regression_data = ColScaler.fit_transform(Kelvin_minute_micrograph_dropna)\n",
    "\n",
    "scaled_regression_data.rename(columns ={'remainder__path':'path', \n",
    "                                        'remainder__sample_id':'sample_id', \n",
    "                                        'remainder__sample_weights':'sample_weights',\n",
    "                                        'remainder__cool_method':'cool_method',\n",
    "                                        'scaler__inverse_anneal_temperature_Kelvin':'inverse_anneal_temperature_Kelvin',\n",
    "                                        'scaler__log_time':'log_time'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fe3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding the cooling methods\n",
    "ohe = pd.get_dummies(scaled_regression_data['cool_method'])\n",
    "dummies = list(ohe.columns.unique())\n",
    "\n",
    "scaled_regression_data = scaled_regression_data.join(ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_regression_preweight, test_regression_preweight = train_test_split(scaled_regression_data, \n",
    "                                         test_size = 0.1, \n",
    "                                         stratify = scaled_regression_data['sample_id'], \n",
    "                                         random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighting the samples based on Sample Id's\n",
    "\n",
    "sample_weights = compute_class_weight(class_weight = 'balanced',\n",
    "                                     classes = train_regression_preweight['sample_id'].unique(),\n",
    "                                     y = train_regression_preweight['sample_id'])\n",
    "\n",
    "SAMPLE_WEIGHTS = pd.DataFrame(zip(train_regression_preweight['sample_id'].unique(),sample_weights), columns = ['sample_id','sample_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attaching sample weights to dataframes for ImageDataGenerator\n",
    "\n",
    "train_regression = pd.merge(train_regression_preweight, SAMPLE_WEIGHTS, on = 'sample_id')\n",
    "test_regression = pd.merge(test_regression_preweight, SAMPLE_WEIGHTS, on = 'sample_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e85e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_DATAFRAME = train_regression\n",
    "DIRECTORY = 'micrographs'\n",
    "REG_XCOL = 'path'\n",
    "REG_YCOL = ['inverse_anneal_temperature_Kelvin','log_time'] + dummies\n",
    "TARGET_SIZE = (522,645)\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdd037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_generator = ImageDataGenerator()\n",
    "validation_generator = ImageDataGenerator()\n",
    "test_datagenerator = ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_regression_generator = data_generator.flow_from_dataframe(dataframe = REG_DATAFRAME,\n",
    "                                                directory = DIRECTORY,\n",
    "                                                x_col = REG_XCOL,\n",
    "                                                y_col = REG_YCOL,\n",
    "                                                class_mode= 'raw',\n",
    "                                                color_mode = 'rgb',\n",
    "                                                sample_weights = 'sample_weights',\n",
    "                                                target_size = TARGET_SIZE,\n",
    "                                                batch_size = 32)\n",
    "\n",
    "validation_regression_generator = validation_generator.flow_from_dataframe(dataframe = REG_DATAFRAME,\n",
    "                                                directory = DIRECTORY,\n",
    "                                                x_col = REG_XCOL,\n",
    "                                                y_col = REG_YCOL,\n",
    "                                                class_mode = 'raw',\n",
    "                                                color_mode = 'rgb',\n",
    "                                                sample_weights = 'sample_weights',\n",
    "                                                target_size = TARGET_SIZE,\n",
    "                                                batch_size = 32)\n",
    "\n",
    "\n",
    "test_regression_generator = test_datagenerator.flow_from_dataframe(dataframe = test_regression,\n",
    "                                                        directory = DIRECTORY,\n",
    "                                                        x_col = REG_XCOL,\n",
    "                                                        y_col = REG_YCOL,\n",
    "                                                        class_mode = 'raw',\n",
    "                                                        color_mode = 'rgb',\n",
    "                                                        shuffle = False,\n",
    "                                                        target_size = TARGET_SIZE,\n",
    "                                                        batch_size = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inception model that accepts the images cropped to (482,645) to remove annotations from training data\n",
    "\n",
    "inception_crop = keras.applications.inception_v3.InceptionV3(include_top = False, \n",
    "                                                                weights = 'imagenet', \n",
    "                                                                input_shape = (482,645,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making inception layers undtrainable for intial phase of model training\n",
    "\n",
    "for layer in inception_crop.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inception_regression_model_builder(training_data):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(tf.keras.Input(shape=(522,645,3)))\n",
    "    model.add(layers.Rescaling(scale = 1./255))\n",
    "    \n",
    "    #Cropping image to remove image annotations\n",
    "    model.add(layers.Cropping2D(\n",
    "              cropping=((0, 40), (0, 0))\n",
    "                ))\n",
    "    #Data Augmentation\n",
    "    model.add(layers.RandomFlip())\n",
    "    model.add(layers.RandomRotation(factor = 0.4, \n",
    "                                    fill_mode = 'reflect'))\n",
    "    model.add(layers.RandomZoom(.4,.2))\n",
    "    model.add(layers.RandomContrast(.2)) \n",
    "    model.add(layers.RandomTranslation(.2,.2,fill_mode='reflect',interpolation='bilinear'))\n",
    "    \n",
    "    #inception layer\n",
    "    model.add(inception_crop)\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "\n",
    "    #Dense Layers\n",
    "    model.add(layers.Dense(1000, activation = None))\n",
    "\n",
    "    model.add(layers.BatchNormalization(momentum=.99))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Dropout(.5))\n",
    "    \n",
    "    \n",
    "    model.add(layers.Dense(500 , activation = None))\n",
    "    \n",
    "    model.add(layers.BatchNormalization(momentum=.99))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Dropout(.5))\n",
    "    \n",
    "    model.add(layers.Dense(9))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                loss ='mse',\n",
    "                metrics=[tf.keras.metrics.mean_squared_error]\n",
    "                 )\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_regression_model = inception_regression_model_builder(train_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_regression_model_fit = inception_regression_model.fit(train_regression_generator,\n",
    "                                                                steps_per_epoch = train_regression_generator.samples/BATCH_SIZE,\n",
    "                                                                epochs = 1,\n",
    "                                                                validation_data = validation_regression_generator,\n",
    "                                                                validation_steps = validation_regression_generator.samples/BATCH_SIZE,\n",
    "                                                                callbacks =  None\n",
    "                                                                )\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa83baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_regression_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0843468",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_regression_model = tf.keras.models.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10369886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is used for fine-tuning the inception model \n",
    "\n",
    "for layer in inception_regression_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = inception_regression_model.evaluate(test_regression_generator)\n",
    "model_evals.append(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050faea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79127832",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_2 =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939248a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_samples = len(test_regression)\n",
    "\n",
    "predict = inception_regression_model.predict(test_regression_generator,nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555693c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_r2 = r2_score(test_regression['inverse_anneal_temperature_Kelvin'],predict[:,0])\n",
    "time_r2 = r2_score(test_regression['log_time'],predict[:,1])\n",
    "r2_scores_2.append((temp_r2,time_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_2[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_transform = ColScaler.named_transformers_['scaler'].inverse_transform(predict[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a60730",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unscaled =  ColScaler.named_transformers_['scaler']\\\n",
    "                          .inverse_transform(test_regression[['inverse_anneal_temperature_Kelvin',\n",
    "                                                              'log_time']])\n",
    "temps = 1/test_unscaled[:,0]\n",
    "times = np.exp(test_unscaled[:,1])\n",
    "                                        \n",
    "test_check = pd.DataFrame({'temperature':temps,'time': times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fdbc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "predict_df = pd.DataFrame(predict_transform, columns = ['inverse_temperature','anneal_time_minutes'])\n",
    "predict_df['time'] = predict_df['anneal_time_minutes'].apply(lambda x: np.exp(x))\n",
    "predict_df['temperature'] = 1/predict_df['inverse_temperature']\n",
    "predict_df['test_temperature'] = test_check['temperature']\n",
    "predict_df['test_time'] = test_check['time']\n",
    "predict_df['delta time'] =  predict_df['time'] - predict_df['test_time'] \n",
    "predict_df['delta temperature'] =  predict_df['temperature'] - predict_df['test_temperature'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c912215",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = -150\n",
    "\n",
    "predict_df_chart = alt.Chart(predict_df).mark_point(color = 'orangered').encode(\n",
    "    x = alt.X('delta time', \n",
    "              axis = alt.Axis(offset = offset, title ='Time Difference (Minutes)', titleY = 175),\n",
    "              scale = alt.Scale(domain=[-1000, 1000])),\n",
    "              \n",
    "    y = alt.Y('delta temperature', \n",
    "              axis = alt.Axis(offset = offset,title ='Temperature Difference (K)',titleX = -175),\n",
    "              scale = alt.Scale(domain=[-100, 100])),\n",
    "    \n",
    "  \n",
    ")\n",
    "\n",
    "\n",
    "predict_df_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56cfa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mae = mean_absolute_error(predict_df['temperature'],test_check['temperature'])\n",
    "time_mae = mean_absolute_error(predict_df['time'],test_check['time'])\n",
    "mae_list.append((temp_mae,time_mae))\n",
    "mae_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc06a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
